{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Huggingface Model\n",
    "\n",
    "| Model | BertForMaskedLM | TFAutoModelWithLMHead |\n",
    "| --- | --- |\n",
    "| 모델 불러오기(local/huggingface) | BertForMaskedLM.from_pretrained('') | TFAutoModelWithLMHead('') |\n",
    "| 모델 저장하기 | BerfForMaskedLM.save_pretrained('*.pt') | TFAutoModelWithLMHead('*.h5') |\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a43e0cac72a487ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c2264f1f6f4cfb"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "cuda_device = None\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = \"cuda\"\n",
    "\tdevice_no = torch.cuda.current_device()\n",
    "\tprint(f\"{torch.cuda.get_device_name(device_no)}\")\n",
    "\tcuda_device = f\"{device}:{device_no}\"\n",
    "\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T08:01:58.533922200Z",
     "start_time": "2023-08-01T08:01:57.500172900Z"
    }
   },
   "id": "98fbb8ae422c5b90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use a Pipeline as a High-Level Helper"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81412aacd1b42da2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin C:\\Users\\jongg\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97b4351d86ed46b9ad4172e0309a0839"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jongg\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jongg\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)fetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e687ee25fab4c3bb7f0094a8aecbe7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading shards:   0%|          | 0/28 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59977342543840fc9650becdd1f6e3c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/884M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdea4f425c0b436593e5344b89fc8b65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2df9a68ae62e42938fda43d30b499433"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e798d05b8aa47f8b527a41daaeabced"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42746539ac854ec49ede901525bac227"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bab222d23ec540e7b6271d8f2089371f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b73cc4bdf6254c9faf478921fc64dc04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc2a700d0f8f44e49ebef18bc3ff8fbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c69bb57849f419782228d6c0a7a5909"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3b8d2f6b42643d0b8521719a027842b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ea10a17ad4d48e588106e4ee7c5dae5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cf7b85e6f6c4456b462331246b5e0ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05b493b7fe1a4abfa6ee2f93164f76b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee52843262294db59f561874aeebf68a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2731287d409d4d85b74348285b73ae45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30c067593d0d4e8fb42a9ad37e694d35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a779f082c75449a7bc5d87e78b8c434e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87e478f7c66c4c699272ee08bea82b6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f0df61f13534b6499a7d05a86ee0ece"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc5a24d2f76d489ea827496b1db70c8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cee791c773c6457b8e793c96d79f4f1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35610cbe040d4d6191f1d60e5d57b1f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e11dab3e8d7f465e959c9f0dd6afbd8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7182fce487014a3e942280806a4cdaa2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "880aaedc60df44f6b1092116b2079c5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaa89ba9d634448da9d2bd9111be5f57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/970M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89eea4795e9b4dd8af4c0a9baac69c68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/933M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "123813a11cc44f148be67834d83e09e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)of-00028.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79d32c73aaec47309d74e1036dda6ee4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 10\u001B[0m\n\u001B[0;32m      5\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;124;03mreturn TextGenerationPipeline\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m pipe \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext-generation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbeomi/kollama-13b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcuda_device\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:788\u001B[0m, in \u001B[0;36mpipeline\u001B[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001B[0m\n\u001B[0;32m    786\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m framework \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    787\u001B[0m     model_classes \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m: targeted_task[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m: targeted_task[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m]}\n\u001B[1;32m--> 788\u001B[0m     framework, model \u001B[38;5;241m=\u001B[39m \u001B[43minfer_framework_load_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframework\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframework\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    798\u001B[0m model_config \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\n\u001B[0;32m    799\u001B[0m hub_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39m_commit_hash\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:269\u001B[0m, in \u001B[0;36minfer_framework_load_model\u001B[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001B[0m\n\u001B[0;32m    263\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m    264\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    265\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrying to load the model with Tensorflow.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    266\u001B[0m     )\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 269\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    271\u001B[0m         model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:493\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    492\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[1;32m--> 493\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    497\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    498\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    499\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:2700\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   2697\u001B[0m     init_contexts\u001B[38;5;241m.\u001B[39mappend(init_empty_weights())\n\u001B[0;32m   2699\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(init_contexts):\n\u001B[1;32m-> 2700\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2702\u001B[0m \u001B[38;5;66;03m# Check first if we are `from_pt`\u001B[39;00m\n\u001B[0;32m   2703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_keep_in_fp32_modules:\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:732\u001B[0m, in \u001B[0;36mLlamaForCausalLM.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m    730\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, config):\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(config)\n\u001B[1;32m--> 732\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mLlamaModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    733\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpretraining_tp \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mpretraining_tp\n\u001B[0;32m    734\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab_size \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mvocab_size\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:561\u001B[0m, in \u001B[0;36mLlamaModel.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab_size \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mvocab_size\n\u001B[0;32m    560\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_tokens \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbedding(config\u001B[38;5;241m.\u001B[39mvocab_size, config\u001B[38;5;241m.\u001B[39mhidden_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_idx)\n\u001B[1;32m--> 561\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mModuleList(\u001B[43m[\u001B[49m\u001B[43mLlamaDecoderLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_hidden_layers\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm \u001B[38;5;241m=\u001B[39m LlamaRMSNorm(config\u001B[38;5;241m.\u001B[39mhidden_size, eps\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mrms_norm_eps)\n\u001B[0;32m    564\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_checkpointing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:561\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab_size \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mvocab_size\n\u001B[0;32m    560\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_tokens \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbedding(config\u001B[38;5;241m.\u001B[39mvocab_size, config\u001B[38;5;241m.\u001B[39mhidden_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_idx)\n\u001B[1;32m--> 561\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mModuleList([\u001B[43mLlamaDecoderLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(config\u001B[38;5;241m.\u001B[39mnum_hidden_layers)])\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm \u001B[38;5;241m=\u001B[39m LlamaRMSNorm(config\u001B[38;5;241m.\u001B[39mhidden_size, eps\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mrms_norm_eps)\n\u001B[0;32m    564\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_checkpointing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:375\u001B[0m, in \u001B[0;36mLlamaDecoderLayer.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mhidden_size\n\u001B[1;32m--> 375\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_attn \u001B[38;5;241m=\u001B[39m \u001B[43mLlamaAttention\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp \u001B[38;5;241m=\u001B[39m LlamaMLP(config)\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_layernorm \u001B[38;5;241m=\u001B[39m LlamaRMSNorm(config\u001B[38;5;241m.\u001B[39mhidden_size, eps\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mrms_norm_eps)\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:254\u001B[0m, in \u001B[0;36mLlamaAttention.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_proj \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_proj \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_key_value_heads \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 254\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_key_value_heads\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mo_proj \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_rope()\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:101\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[1;34m(self, in_features, out_features, bias, device, dtype)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister_parameter(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbias\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 101\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:107\u001B[0m, in \u001B[0;36mLinear.reset_parameters\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreset_parameters\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001B[39;00m\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001B[39;00m\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001B[39;00m\n\u001B[1;32m--> 107\u001B[0m     \u001B[43minit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkaiming_uniform_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    109\u001B[0m         fan_in, _ \u001B[38;5;241m=\u001B[39m init\u001B[38;5;241m.\u001B[39m_calculate_fan_in_and_fan_out(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight)\n",
      "File \u001B[1;32m~\\PycharmProjects\\HuggingFaceKoLLaMa13b\\venv\\Lib\\site-packages\\torch\\nn\\init.py:412\u001B[0m, in \u001B[0;36mkaiming_uniform_\u001B[1;34m(tensor, a, mode, nonlinearity)\u001B[0m\n\u001B[0;32m    410\u001B[0m bound \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m3.0\u001B[39m) \u001B[38;5;241m*\u001B[39m std  \u001B[38;5;66;03m# Calculate uniform bounds from standard deviation\u001B[39;00m\n\u001B[0;32m    411\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muniform_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mbound\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbound\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\"\n",
    "return TextGenerationPipeline\n",
    "\"\"\"\n",
    "pipe = pipeline(\"text-generation\", model = \"beomi/kollama-13b\", device = cuda_device, num_workers = 8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T08:09:05.986160600Z",
     "start_time": "2023-08-01T08:02:05.372869Z"
    }
   },
   "id": "68b62144e8fb9999"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "94511f7977575796"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
